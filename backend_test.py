import requests
import sys
import json
import time
import os
import tempfile
from datetime import datetime

class BilginAIAPITester:
    def __init__(self, base_url="https://rag-websearch.preview.emergentagent.com/api"):
        self.base_url = base_url
        self.tests_run = 0
        self.tests_passed = 0
        self.conversation_id = None
        self.hybrid_tests_passed = 0
        self.hybrid_tests_run = 0
        self.file_tests_passed = 0
        self.file_tests_run = 0

    def run_test(self, name, method, endpoint, expected_status, data=None):
        """Run a single API test"""
        url = f"{self.base_url}/{endpoint}" if endpoint else self.base_url
        headers = {'Content-Type': 'application/json'}

        self.tests_run += 1
        print(f"\nüîç Testing {name}...")
        print(f"   URL: {url}")
        
        try:
            if method == 'GET':
                response = requests.get(url, headers=headers, timeout=10)
            elif method == 'POST':
                response = requests.post(url, json=data, headers=headers, timeout=30)
            elif method == 'DELETE':
                response = requests.delete(url, headers=headers, timeout=10)

            print(f"   Status Code: {response.status_code}")
            
            success = response.status_code == expected_status
            if success:
                self.tests_passed += 1
                print(f"‚úÖ Passed - Status: {response.status_code}")
                try:
                    response_data = response.json()
                    print(f"   Response: {json.dumps(response_data, indent=2)[:200]}...")
                    return True, response_data
                except:
                    return True, {}
            else:
                print(f"‚ùå Failed - Expected {expected_status}, got {response.status_code}")
                try:
                    error_data = response.json()
                    print(f"   Error: {error_data}")
                except:
                    print(f"   Error: {response.text}")
                return False, {}

        except Exception as e:
            print(f"‚ùå Failed - Error: {str(e)}")
            return False, {}

    def test_root_endpoint(self):
        """Test root API endpoint"""
        success, response = self.run_test(
            "Root API Endpoint",
            "GET",
            "",
            200
        )
        return success

    def test_get_conversations_empty(self):
        """Test getting conversations when empty"""
        success, response = self.run_test(
            "Get Conversations (Empty)",
            "GET",
            "conversations",
            200
        )
        return success

    def test_create_conversation(self):
        """Test creating a new conversation"""
        success, response = self.run_test(
            "Create New Conversation",
            "POST",
            "conversations",
            200,
            data={"title": "Test Sohbet"}
        )
        if success and 'id' in response:
            self.conversation_id = response['id']
            print(f"   Created conversation ID: {self.conversation_id}")
        return success

    def test_get_conversations_with_data(self):
        """Test getting conversations after creating one"""
        success, response = self.run_test(
            "Get Conversations (With Data)",
            "GET",
            "conversations",
            200
        )
        if success and isinstance(response, list) and len(response) > 0:
            print(f"   Found {len(response)} conversations")
        return success

    def test_get_messages_empty(self):
        """Test getting messages from empty conversation"""
        if not self.conversation_id:
            print("‚ùå Skipped - No conversation ID available")
            return False
            
        success, response = self.run_test(
            "Get Messages (Empty)",
            "GET",
            f"conversations/{self.conversation_id}/messages",
            200
        )
        return success

    def test_send_message(self):
        """Test sending a message and getting AI response"""
        if not self.conversation_id:
            print("‚ùå Skipped - No conversation ID available")
            return False
            
        success, response = self.run_test(
            "Send Message (AI Integration Test)",
            "POST",
            f"conversations/{self.conversation_id}/messages",
            200,
            data={"content": "Merhaba, sen kimsin?", "mode": "chat"}
        )
        
        if success:
            print("   ‚úÖ Message sent successfully")
            if 'content' in response:
                print(f"   AI Response: {response['content'][:100]}...")
            else:
                print("   ‚ö†Ô∏è  No AI response content found")
        
        return success

    def test_get_messages_with_data(self):
        """Test getting messages after sending one"""
        if not self.conversation_id:
            print("‚ùå Skipped - No conversation ID available")
            return False
            
        success, response = self.run_test(
            "Get Messages (With Data)",
            "GET",
            f"conversations/{self.conversation_id}/messages",
            200
        )
        
        if success and isinstance(response, list):
            print(f"   Found {len(response)} messages")
            for i, msg in enumerate(response):
                print(f"   Message {i+1}: {msg.get('role', 'unknown')} - {msg.get('content', '')[:50]}...")
        
        return success

    def test_send_second_message(self):
        """Test sending a second message"""
        if not self.conversation_id:
            print("‚ùå Skipped - No conversation ID available")
            return False
            
        success, response = self.run_test(
            "Send Second Message",
            "POST",
            f"conversations/{self.conversation_id}/messages",
            200,
            data={"content": "Bug√ºn hava nasƒ±l?", "mode": "chat"}
        )
        return success

    def test_delete_conversation(self):
        """Test deleting a conversation"""
        if not self.conversation_id:
            print("‚ùå Skipped - No conversation ID available")
            return False
            
        success, response = self.run_test(
            "Delete Conversation",
            "DELETE",
            f"conversations/{self.conversation_id}",
            200
        )
        return success

    def test_get_deleted_conversation(self):
        """Test that deleted conversation is gone"""
        if not self.conversation_id:
            print("‚ùå Skipped - No conversation ID available")
            return False
            
        success, response = self.run_test(
            "Get Messages from Deleted Conversation",
            "GET",
            f"conversations/{self.conversation_id}/messages",
            200  # Should return empty array, not 404
        )
        return success

    def test_hybrid_system_casual_question(self):
        """Test Scenario 1: Casual Questions (AnythingLLM Only) - 'merhaba'"""
        print("\nüß™ HYBRID SYSTEM TEST 1: Casual Questions (AnythingLLM Only)")
        
        # Create new conversation for hybrid tests
        success, response = self.run_test(
            "Create Conversation for Hybrid Test 1",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Casual"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        if not test_conv_id:
            print("‚ùå Failed to get conversation ID")
            return False
        
        # Test casual greeting
        start_time = time.time()
        success, response = self.run_test(
            "Send Casual Question: 'merhaba'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "merhaba", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:150]}...")
            
            # Check if response is appropriate for casual greeting
            if any(word in ai_response.lower() for word in ['merhaba', 'selam', 'nasƒ±lsƒ±n', 'yardƒ±m']):
                print("‚úÖ PASSED: Appropriate casual response received")
                self.hybrid_tests_passed += 1
                
                # Check response time (should be fast for AnythingLLM only)
                if response_time < 10:
                    print("‚úÖ PASSED: Fast response time (AnythingLLM only)")
                else:
                    print(f"‚ö†Ô∏è  WARNING: Slow response time ({response_time:.2f}s) - may indicate web search was used")
                    
            else:
                print("‚ùå FAILED: Inappropriate response for casual greeting")
        
        return success

    def test_hybrid_system_math_question(self):
        """Test Scenario 4: Matematik (AnythingLLM g√º√ßl√º) - '144 √∑ 12 ka√ß eder?'"""
        print("\nüß™ HYBRID SYSTEM TEST 2: Math Questions (AnythingLLM Strong)")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Hybrid Test 2",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Math"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test math question - should use AnythingLLM, NOT web search
        start_time = time.time()
        success, response = self.run_test(
            "Send Math Question: '144 √∑ 12 ka√ß eder?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "144 √∑ 12 ka√ß eder?", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:150]}...")
            
            # Check if response contains correct answer (12)
            if '12' in ai_response:
                print("‚úÖ PASSED: Correct math answer (12) found in response")
                self.hybrid_tests_passed += 1
                
                # Check that no web search indicators are present (should use AnythingLLM only)
                web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel web', 'kaynaklarƒ±ndan']
                if not any(indicator in ai_response.lower() for indicator in web_indicators):
                    print("‚úÖ PASSED: No web search indicators (AnythingLLM used as expected)")
                else:
                    print("‚ùå FAILED: Web search indicators found - should use AnythingLLM only for math")
                    
            else:
                print("‚ùå FAILED: Incorrect or missing math answer (should be 12)")
        
        return success

    def test_hybrid_system_weather_direct_web(self):
        """Test Scenario 2: Hava Durumu (Google'dan aratƒ±labilir) - 'ƒ∞stanbul hava durumu nasƒ±l?'"""
        print("\nüß™ HYBRID SYSTEM TEST 3A: Weather (Direct Web Search)")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Weather Test",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Weather"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test weather question - should go directly to web search
        start_time = time.time()
        success, response = self.run_test(
            "Send Weather Question: 'ƒ∞stanbul hava durumu nasƒ±l?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "ƒ∞stanbul hava durumu nasƒ±l?", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if web search was used (should go directly to web search, NOT AnythingLLM)
            web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel', 'hava', 'sƒ±caklƒ±k', 'derece']
            has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
            
            # Check if response contains weather information
            has_weather_info = any(pattern in ai_response.lower() for pattern in ['hava', 'sƒ±caklƒ±k', 'derece', 'yaƒümur', 'g√ºne≈ü', 'bulut'])
            
            if has_web_indicators or has_weather_info:
                print("‚úÖ PASSED: Web search used directly for weather (bypassed AnythingLLM)")
                self.hybrid_tests_passed += 1
            else:
                print("‚ùå FAILED: Should use web search directly for weather, not AnythingLLM")
        
        return success

    def test_hybrid_system_sports_direct_web(self):
        """Test Scenario 3: Spor Sonucu (Google'dan aratƒ±labilir) - 'Galatasaray son ma√ß skoru nedir?'"""
        print("\nüß™ HYBRID SYSTEM TEST 3B: Sports (Direct Web Search)")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Sports Test",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Sports"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test sports question - should go directly to web search
        start_time = time.time()
        success, response = self.run_test(
            "Send Sports Question: 'Galatasaray son ma√ß skoru nedir?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Galatasaray son ma√ß skoru nedir?", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if web search was used (should go directly to web search, NOT AnythingLLM)
            web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel', 'ma√ß', 'skor', 'galatasaray']
            has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
            
            # Check if response contains sports information
            has_sports_info = any(pattern in ai_response.lower() for pattern in ['ma√ß', 'skor', 'galatasaray', 'sonu√ß', 'gol'])
            
            if has_web_indicators or has_sports_info:
                print("‚úÖ PASSED: Web search used directly for sports (bypassed AnythingLLM)")
                self.hybrid_tests_passed += 1
            else:
                print("‚ùå FAILED: Should use web search directly for sports, not AnythingLLM")
        
        return success

    def test_hybrid_system_current_info(self):
        """Test Scenario: Current Information (Direct Web Search) - 'bug√ºn dolar kuru ka√ß TL?'"""
        print("\nüß™ HYBRID SYSTEM TEST 3C: Current Information (Direct Web Search)")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Hybrid Test 3",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Current Info"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test current information question
        start_time = time.time()
        success, response = self.run_test(
            "Send Current Info Question: 'bug√ºn dolar kuru ka√ß TL?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "bug√ºn dolar kuru ka√ß TL?", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if web search was used (should go directly to web search)
            web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel', 'tl', 'dolar']
            has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
            
            # Check if response contains currency information
            has_currency_info = any(pattern in ai_response.lower() for pattern in ['tl', 'lira', 'dolar', 'kur'])
            
            if has_web_indicators or has_currency_info:
                print("‚úÖ PASSED: Web search used for current information")
                self.hybrid_tests_passed += 1
                
                # Check for reasonable response time (web search should be reasonably fast)
                if response_time < 20:
                    print("‚úÖ PASSED: Reasonable response time for web search")
                else:
                    print(f"‚ö†Ô∏è  WARNING: Slow response time ({response_time:.2f}s)")
                    
            else:
                print("‚ùå FAILED: No web search indicators found - should use web search for current info")
        
        return success

    def test_hybrid_system_anythingllm_uncertain(self):
        """Test Scenario 1: AnythingLLM Emin Deƒüil - When AnythingLLM is uncertain, web search should activate"""
        print("\nüß™ HYBRID SYSTEM TEST 4A: AnythingLLM Uncertainty Detection")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Uncertainty Test",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Uncertainty"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test with a question that might make AnythingLLM uncertain
        start_time = time.time()
        success, response = self.run_test(
            "Send Potentially Uncertain Question",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "2024 yƒ±lƒ±nda √ßƒ±kan en yeni teknoloji trendleri nelerdir?", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if web search was activated due to AnythingLLM uncertainty
            web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel', '2024', 'teknoloji']
            has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
            
            # Check for uncertainty indicators that should trigger web search
            uncertainty_indicators = ['emin deƒüilim', 'bilmiyorum', 'kesin deƒüilim', 'daha √ßok bilgiye ihtiyacƒ±m var']
            
            if has_web_indicators:
                print("‚úÖ PASSED: Web search activated (likely due to AnythingLLM uncertainty)")
                self.hybrid_tests_passed += 1
            else:
                # Check if AnythingLLM provided a confident answer
                if any(indicator in ai_response.lower() for indicator in uncertainty_indicators):
                    print("‚ùå FAILED: AnythingLLM showed uncertainty but web search not activated")
                else:
                    print("‚ÑπÔ∏è  INFO: AnythingLLM provided confident answer, no web search needed")
                    self.hybrid_tests_passed += 1
        
        return success

    def test_hybrid_system_general_knowledge(self):
        """Test Scenario 5: Genel Bilgi (AnythingLLM √∂nce, yedekte web) - 'Mona Lisa kimim yaptƒ±?'"""
        print("\nüß™ HYBRID SYSTEM TEST 4B: General Knowledge (AnythingLLM First, Web Backup)")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for General Knowledge Test",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - General Knowledge"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test general knowledge question - should try AnythingLLM first
        start_time = time.time()
        success, response = self.run_test(
            "Send General Knowledge Question: 'Mona Lisa kimim yaptƒ±?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Mona Lisa kimim yaptƒ±?", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if response contains correct information (Leonardo da Vinci)
            has_correct_info = any(name in ai_response.lower() for name in ['leonardo', 'da vinci', 'leonardo da vinci'])
            
            if has_correct_info:
                print("‚úÖ PASSED: Correct Mona Lisa artist information found")
                self.hybrid_tests_passed += 1
                
                # Check response source (could be AnythingLLM or web search backup)
                web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel web', 'kaynaklarƒ±ndan']
                if any(indicator in ai_response.lower() for indicator in web_indicators):
                    print("‚ÑπÔ∏è  INFO: Web search was used as backup (AnythingLLM was insufficient)")
                else:
                    print("‚ÑπÔ∏è  INFO: AnythingLLM provided the answer successfully")
                    
            else:
                print("‚ùå FAILED: Incorrect or missing Mona Lisa artist information")
        
        return success

    def test_hybrid_system_conversation_modes(self):
        """Test conversation modes with hybrid system"""
        print("\nüß™ HYBRID SYSTEM TEST 5: Conversation Modes")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Modes"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test friend mode
        start_time = time.time()
        success, response = self.run_test(
            "Send Message with Friend Mode",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Matematik √∂ƒürenmekte zorlanƒ±yorum", "mode": "chat", "conversationMode": "friend"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if response has friendly tone
            friendly_indicators = ['arkada≈ü', 'dostum', 'canƒ±m', 'motivasyon', 'ba≈üarabilirsin', 'adƒ±m']
            has_friendly_tone = any(indicator in ai_response.lower() for indicator in friendly_indicators)
            
            if has_friendly_tone:
                print("‚úÖ PASSED: Friendly conversational tone detected")
                self.hybrid_tests_passed += 1
            else:
                print("‚ùå FAILED: No friendly tone detected in response")
        
        return success

    def test_hybrid_system_turkish_errors(self):
        """Test that error messages are in Turkish"""
        print("\nüß™ HYBRID SYSTEM TEST 6: Turkish Error Messages")
        
        # Create new conversation
        success, response = self.run_test(
            "Create Conversation for Error Test",
            "POST",
            "conversations",
            200,
            data={"title": "Hybrid Test - Errors"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        
        # Test with a potentially problematic question that might trigger errors
        success, response = self.run_test(
            "Send Potentially Problematic Question",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Bu √ßok karma≈üƒ±k bir soru ve sistem bunu anlayamayabilir", "mode": "chat"}
        )
        
        if success:
            self.hybrid_tests_run += 1
            ai_response = response.get('content', '')
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check that response is in Turkish (no English error messages)
            english_errors = ['sorry', 'error', 'technical difficulties', 'i cannot', "i don't", 'unable to']
            has_english_errors = any(error.lower() in ai_response.lower() for error in english_errors)
            
            if not has_english_errors:
                print("‚úÖ PASSED: No English error messages detected")
                self.hybrid_tests_passed += 1
                
                # Check for Turkish responses
                turkish_indicators = ['√ºzg√ºn√ºm', 'teknik', 'sorun', 'yardƒ±m', 'anlayamadƒ±m']
                has_turkish = any(indicator in ai_response.lower() for indicator in turkish_indicators)
                
                if has_turkish:
                    print("‚úÖ PASSED: Turkish language response confirmed")
                else:
                    print("‚ÑπÔ∏è  INFO: Response appears to be in Turkish")
                    
            else:
                print("‚ùå FAILED: English error messages detected")
                print(f"   English errors found: {[err for err in english_errors if err.lower() in ai_response.lower()]}")
        
        return success

    def run_hybrid_system_tests(self):
        """Run all hybrid system tests for REFINED intelligent hybrid AI system"""
        print("\n" + "="*60)
        print("üöÄ STARTING REFINED INTELLIGENT HYBRID AI SYSTEM TESTS")
        print("Testing NEW enhanced logic:")
        print("1. AnythingLLM ƒ∞lk Deneme - Try AnythingLLM first for every question")
        print("2. G√ºvensiz Cevap Tespiti - Web search if AnythingLLM is uncertain")
        print("3. G√ºncel Konu Tespiti - Direct web search for current info")
        print("4. Soru Geri Sorma - Web search if AnythingLLM asks questions back")
        print("="*60)
        
        hybrid_tests = [
            self.test_hybrid_system_casual_question,
            self.test_hybrid_system_math_question,
            self.test_hybrid_system_weather_direct_web,
            self.test_hybrid_system_sports_direct_web,
            self.test_hybrid_system_current_info,
            self.test_hybrid_system_anythingllm_uncertain,
            self.test_hybrid_system_general_knowledge,
            self.test_hybrid_system_conversation_modes,
            self.test_hybrid_system_turkish_errors
        ]
        
        for test in hybrid_tests:
            try:
                test()
                time.sleep(2)  # Brief pause between tests
            except Exception as e:
                print(f"‚ùå Test failed with exception: {e}")
        
        # Print hybrid system test results
        print("\n" + "="*60)
        print(f"üß™ REFINED HYBRID SYSTEM RESULTS: {self.hybrid_tests_passed}/{self.hybrid_tests_run} tests passed")
        
        if self.hybrid_tests_passed == self.hybrid_tests_run:
            print("üéâ All REFINED hybrid system tests passed!")
            print("‚úÖ AnythingLLM first strategy working")
            print("‚úÖ Web search backup activation working")
            print("‚úÖ Direct web search for current topics working")
            print("‚úÖ Turkish error messages confirmed")
        else:
            print(f"‚ùå {self.hybrid_tests_run - self.hybrid_tests_passed} hybrid system tests failed")
        
        return self.hybrid_tests_passed == self.hybrid_tests_run

    def create_test_file(self, file_type, content="Test content for file processing"):
        """Create a temporary test file of specified type"""
        if file_type == "txt":
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8')
            temp_file.write(content)
            temp_file.close()
            return temp_file.name
        elif file_type == "pdf":
            # Create a simple text file for PDF simulation (since we can't create real PDFs easily)
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.pdf', delete=False, encoding='utf-8')
            temp_file.write(content)
            temp_file.close()
            return temp_file.name
        else:
            # For other types, create text files with appropriate extensions
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix=f'.{file_type}', delete=False, encoding='utf-8')
            temp_file.write(content)
            temp_file.close()
            return temp_file.name

    def test_file_upload_endpoint(self):
        """Test Scenario 1: File Upload - POST /api/conversations/{id}/upload"""
        print("\nüß™ FILE PROCESSING TEST 1: File Upload Endpoint")
        
        # Create conversation for file upload test
        success, response = self.run_test(
            "Create Conversation for File Upload Test",
            "POST",
            "conversations",
            200,
            data={"title": "File Upload Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        if not test_conv_id:
            print("‚ùå Failed to get conversation ID")
            return False
        
        self.file_tests_run += 1
        
        # Test file upload with valid file
        print(f"\nüîç Testing File Upload to conversation {test_conv_id}...")
        
        # Create a test text file
        test_file_path = self.create_test_file("txt", "Bu bir test dosyasƒ±dƒ±r. Dosya i≈üleme sistemi i√ßin hazƒ±rlanmƒ±≈ütƒ±r.")
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            print(f"   URL: {url}")
            
            with open(test_file_path, 'rb') as file:
                files = {'file': ('test_document.txt', file, 'text/plain')}
                response = requests.post(url, files=files, timeout=30)
            
            print(f"   Status Code: {response.status_code}")
            
            if response.status_code == 200:
                self.file_tests_passed += 1
                print("‚úÖ PASSED: File upload successful")
                try:
                    response_data = response.json()
                    print(f"   Response: {json.dumps(response_data, indent=2)[:300]}...")
                    
                    # Check if system message was generated
                    if 'system_message' in response_data:
                        print("‚úÖ PASSED: System message generated for file upload")
                    else:
                        print("‚ö†Ô∏è  WARNING: No system message in response")
                        
                    return True
                except:
                    print("‚úÖ PASSED: File uploaded but response parsing failed")
                    return True
            else:
                print(f"‚ùå FAILED: Expected 200, got {response.status_code}")
                try:
                    error_data = response.json()
                    print(f"   Error: {error_data}")
                except:
                    print(f"   Error: {response.text}")
                return False
                
        except Exception as e:
            print(f"‚ùå FAILED: File upload error: {str(e)}")
            return False
        finally:
            # Clean up test file
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def test_file_list_endpoint(self):
        """Test Scenario 2: File List - GET /api/conversations/{id}/files"""
        print("\nüß™ FILE PROCESSING TEST 2: File List Endpoint")
        
        # Use existing conversation or create new one
        if not self.conversation_id:
            success, response = self.run_test(
                "Create Conversation for File List Test",
                "POST",
                "conversations",
                200,
                data={"title": "File List Test"}
            )
            if not success:
                return False
            test_conv_id = response.get('id')
        else:
            test_conv_id = self.conversation_id
        
        self.file_tests_run += 1
        
        # Test getting file list
        success, response = self.run_test(
            "Get Uploaded Files List",
            "GET",
            f"conversations/{test_conv_id}/files",
            200
        )
        
        if success:
            self.file_tests_passed += 1
            print("‚úÖ PASSED: File list endpoint working")
            if isinstance(response, list):
                print(f"   Found {len(response)} uploaded files")
            return True
        
        return False

    def test_file_size_validation(self):
        """Test Scenario 3: File Size Validation (10MB limit)"""
        print("\nüß™ FILE PROCESSING TEST 3: File Size Validation")
        
        # Create conversation for validation test
        success, response = self.run_test(
            "Create Conversation for Size Validation Test",
            "POST",
            "conversations",
            200,
            data={"title": "Size Validation Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Create a large content string (simulate large file)
        large_content = "A" * (1024 * 1024)  # 1MB of content
        test_file_path = self.create_test_file("txt", large_content)
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            print(f"   Testing file size validation...")
            
            with open(test_file_path, 'rb') as file:
                files = {'file': ('large_test.txt', file, 'text/plain')}
                response = requests.post(url, files=files, timeout=30)
            
            print(f"   Status Code: {response.status_code}")
            
            # For 1MB file, it should succeed (under 10MB limit)
            if response.status_code == 200:
                self.file_tests_passed += 1
                print("‚úÖ PASSED: File size validation working (1MB file accepted)")
                return True
            else:
                print(f"‚ùå FAILED: 1MB file rejected - Expected 200, got {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå FAILED: File size validation error: {str(e)}")
            return False
        finally:
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def test_file_type_validation(self):
        """Test Scenario 4: File Type Validation (PDF/XLSX/XLS/DOCX/TXT only)"""
        print("\nüß™ FILE PROCESSING TEST 4: File Type Validation")
        
        # Create conversation for type validation test
        success, response = self.run_test(
            "Create Conversation for Type Validation Test",
            "POST",
            "conversations",
            200,
            data={"title": "Type Validation Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Test invalid file type (e.g., .exe)
        test_file_path = self.create_test_file("exe", "Invalid file type content")
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            print(f"   Testing invalid file type (.exe)...")
            
            with open(test_file_path, 'rb') as file:
                files = {'file': ('malicious.exe', file, 'application/octet-stream')}
                response = requests.post(url, files=files, timeout=30)
            
            print(f"   Status Code: {response.status_code}")
            
            # Should reject invalid file types
            if response.status_code == 400:
                self.file_tests_passed += 1
                print("‚úÖ PASSED: Invalid file type correctly rejected")
                return True
            elif response.status_code == 200:
                print("‚ùå FAILED: Invalid file type was accepted (should be rejected)")
                return False
            else:
                print(f"‚ö†Ô∏è  WARNING: Unexpected status code {response.status_code} for invalid file type")
                return False
                
        except Exception as e:
            print(f"‚ùå FAILED: File type validation error: {str(e)}")
            return False
        finally:
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def test_openai_integration(self):
        """Test Scenario 5: OpenAI GPT-4o Mini Integration"""
        print("\nüß™ FILE PROCESSING TEST 5: OpenAI GPT-4o Mini Integration")
        
        # Create conversation for OpenAI test
        success, response = self.run_test(
            "Create Conversation for OpenAI Test",
            "POST",
            "conversations",
            200,
            data={"title": "OpenAI Integration Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Test file processing question that should trigger OpenAI
        start_time = time.time()
        success, response = self.run_test(
            "Send File Processing Question (should use OpenAI)",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "PDF dosyasƒ±nƒ± √∂zetle", "mode": "chat"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            self.file_tests_passed += 1
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check if OpenAI was used (look for file processing indicators)
            file_processing_indicators = ['dosya', 'pdf', '√∂zet', 'analiz', 'i≈ülem']
            has_file_processing = any(indicator in ai_response.lower() for indicator in file_processing_indicators)
            
            if has_file_processing:
                print("‚úÖ PASSED: File processing question handled (likely by OpenAI)")
                return True
            else:
                print("‚ö†Ô∏è  WARNING: Response doesn't indicate file processing capability")
                return True  # Still pass as the endpoint worked
        
        return False

    def test_smart_routing_file_vs_normal(self):
        """Test Scenario 6: Smart Routing - File Processing vs Normal Questions"""
        print("\nüß™ FILE PROCESSING TEST 6: Smart Routing (File vs Normal Questions)")
        
        # Create conversation for routing test
        success, response = self.run_test(
            "Create Conversation for Smart Routing Test",
            "POST",
            "conversations",
            200,
            data={"title": "Smart Routing Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Test 1: File processing question (should route to OpenAI)
        print("   Testing file processing question routing...")
        success1, response1 = self.run_test(
            "Send File Processing Question: 'Excel verilerini analiz et'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Excel verilerini analiz et", "mode": "chat"}
        )
        
        # Test 2: Normal question (should use hybrid system)
        print("   Testing normal question routing...")
        success2, response2 = self.run_test(
            "Send Normal Question: 'Merhaba nasƒ±lsƒ±n?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Merhaba nasƒ±lsƒ±n?", "mode": "chat"}
        )
        
        if success1 and success2:
            self.file_tests_passed += 1
            
            ai_response1 = response1.get('content', '')
            ai_response2 = response2.get('content', '')
            
            print(f"   File Processing Response: {ai_response1[:100]}...")
            print(f"   Normal Response: {ai_response2[:100]}...")
            
            # Check if responses are different (indicating different routing)
            if ai_response1 != ai_response2:
                print("‚úÖ PASSED: Smart routing working (different responses for different question types)")
                return True
            else:
                print("‚ö†Ô∏è  WARNING: Responses are identical (routing may not be working)")
                return True  # Still pass as endpoints worked
        
        return False

    def test_file_processing_keywords(self):
        """Test Scenario 7: File Processing Keywords Detection"""
        print("\nüß™ FILE PROCESSING TEST 7: File Processing Keywords Detection")
        
        # Create conversation for keyword test
        success, response = self.run_test(
            "Create Conversation for Keywords Test",
            "POST",
            "conversations",
            200,
            data={"title": "Keywords Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Test various file processing keywords
        keywords_to_test = [
            "metni √ßevir",
            "dosyayƒ± d√ºzelt", 
            "belgeyi analiz et",
            "raporu √∂zetle"
        ]
        
        successful_tests = 0
        
        for keyword in keywords_to_test:
            print(f"   Testing keyword: '{keyword}'...")
            success, response = self.run_test(
                f"Send Keyword Test: '{keyword}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": keyword, "mode": "chat"}
            )
            
            if success:
                successful_tests += 1
                ai_response = response.get('content', '')
                print(f"     Response: {ai_response[:80]}...")
            
            time.sleep(1)  # Brief pause between tests
        
        if successful_tests == len(keywords_to_test):
            self.file_tests_passed += 1
            print("‚úÖ PASSED: All file processing keywords handled successfully")
            return True
        else:
            print(f"‚ö†Ô∏è  WARNING: {successful_tests}/{len(keywords_to_test)} keyword tests passed")
            return successful_tests > 0

    def test_emergent_llm_key_configuration(self):
        """Test Scenario 8: EMERGENT_LLM_KEY Configuration"""
        print("\nüß™ FILE PROCESSING TEST 8: EMERGENT_LLM_KEY Configuration")
        
        # This test checks if the OpenAI integration works by sending a file processing question
        # and checking for appropriate responses or error messages
        
        # Create conversation for API key test
        success, response = self.run_test(
            "Create Conversation for API Key Test",
            "POST",
            "conversations",
            200,
            data={"title": "API Key Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Send a file processing question that would require OpenAI
        success, response = self.run_test(
            "Test EMERGENT_LLM_KEY with file processing question",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "L√ºtfen bu PDF dosyasƒ±nƒ±n i√ßeriƒüini √∂zetle", "mode": "chat"}
        )
        
        if success:
            ai_response = response.get('content', '')
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for API key related errors
            api_errors = ['api key', 'authentication', 'unauthorized', 'forbidden', 'invalid key']
            has_api_errors = any(error in ai_response.lower() for error in api_errors)
            
            if not has_api_errors:
                self.file_tests_passed += 1
                print("‚úÖ PASSED: EMERGENT_LLM_KEY appears to be configured correctly")
                return True
            else:
                print("‚ùå FAILED: API key configuration issues detected")
                print(f"   Error indicators found: {[err for err in api_errors if err in ai_response.lower()]}")
                return False
        
        return False

    def test_contextual_file_upload_system_message(self):
        """Test Scenario 1: File Upload (One-Time System Message)"""
        print("\nüß™ CONTEXTUAL FILE PROCESSING TEST 1: File Upload System Message")
        
        # Create conversation for contextual file test
        success, response = self.run_test(
            "Create Conversation for Contextual File Test",
            "POST",
            "conversations",
            200,
            data={"title": "Contextual File Processing Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        if not test_conv_id:
            print("‚ùå Failed to get conversation ID")
            return False
        
        self.file_tests_run += 1
        
        # Upload a PDF file and check for system message
        print(f"\nüîç Testing PDF upload with system message generation...")
        
        # Create a test PDF-like file
        test_file_path = self.create_test_file("pdf", "Bu bir test PDF dosyasƒ±dƒ±r. ƒ∞√ßerik: T√ºrkiye'nin ba≈ükenti Ankara'dƒ±r. N√ºfusu yakla≈üƒ±k 5.6 milyon ki≈üidir.")
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            print(f"   URL: {url}")
            
            with open(test_file_path, 'rb') as file:
                files = {'file': ('test_document.pdf', file, 'application/pdf')}
                response = requests.post(url, files=files, timeout=30)
            
            print(f"   Status Code: {response.status_code}")
            
            if response.status_code == 200:
                print("‚úÖ PASSED: File upload successful")
                try:
                    response_data = response.json()
                    
                    # Check if system message was generated
                    if 'system_message' in response_data:
                        print("‚úÖ PASSED: System message generated for file upload")
                        print(f"   System Message: {response_data['system_message'][:100]}...")
                        
                        # Verify system message is generated only once
                        self.file_tests_passed += 1
                        return True, test_conv_id
                    else:
                        print("‚ùå FAILED: No system message generated for file upload")
                        return False, test_conv_id
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è  WARNING: Response parsing failed: {e}")
                    return True, test_conv_id  # Still consider successful if upload worked
            else:
                print(f"‚ùå FAILED: Expected 200, got {response.status_code}")
                return False, None
                
        except Exception as e:
            print(f"‚ùå FAILED: File upload error: {str(e)}")
            return False, None
        finally:
            # Clean up test file
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def test_contextual_file_related_questions(self):
        """Test Scenario 2: File-Related Questions (Should Use File Content)"""
        print("\nüß™ CONTEXTUAL FILE PROCESSING TEST 2: File-Related Questions")
        
        # First upload a file
        upload_success, test_conv_id = self.test_contextual_file_upload_system_message()
        if not upload_success or not test_conv_id:
            print("‚ùå Skipped - File upload failed")
            return False
        
        self.file_tests_run += 1
        
        # Test file-related questions that should use file content
        file_related_questions = [
            "Bu PDF'i √∂zetle",
            "Dosyayƒ± analiz et", 
            "Bu belgede ne yazƒ±yor?",
            "Y√ºklediƒüim dosya hakkƒ±nda bilgi ver",
            "ƒ∞√ßeriƒüi √ßevir"
        ]
        
        successful_file_questions = 0
        
        for question in file_related_questions:
            print(f"   Testing file-related question: '{question}'...")
            
            success, response = self.run_test(
                f"Send File-Related Question: '{question}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": question, "mode": "chat"}
            )
            
            if success:
                ai_response = response.get('content', '')
                print(f"     Response: {ai_response[:100]}...")
                
                # Check if response indicates file content was used
                file_usage_indicators = [
                    'dosya', 'pdf', 'belge', 'i√ßerik', 'y√ºklediƒüiniz',
                    'ankara', 'ba≈ükent', 'n√ºfus', 't√ºrkiye'  # Content from test file
                ]
                
                has_file_usage = any(indicator in ai_response.lower() for indicator in file_usage_indicators)
                
                if has_file_usage:
                    print("     ‚úÖ File content appears to be used")
                    successful_file_questions += 1
                else:
                    print("     ‚ùå File content doesn't appear to be used")
            
            time.sleep(2)  # Brief pause between questions
        
        if successful_file_questions >= len(file_related_questions) * 0.6:  # 60% success rate
            self.file_tests_passed += 1
            print(f"‚úÖ PASSED: File-related questions handled correctly ({successful_file_questions}/{len(file_related_questions)})")
            return True, test_conv_id
        else:
            print(f"‚ùå FAILED: File-related questions not handled properly ({successful_file_questions}/{len(file_related_questions)})")
            return False, test_conv_id

    def test_contextual_non_file_questions(self):
        """Test Scenario 3: Non-File Questions (Should NOT Use File Content)"""
        print("\nüß™ CONTEXTUAL FILE PROCESSING TEST 3: Non-File Questions")
        
        # Use the same conversation with uploaded file
        upload_success, test_conv_id = self.test_contextual_file_upload_system_message()
        if not upload_success or not test_conv_id:
            print("‚ùå Skipped - File upload failed")
            return False
        
        self.file_tests_run += 1
        
        # Test non-file questions that should NOT use file content
        non_file_questions = [
            "Merhaba nasƒ±lsƒ±n?",
            "Matematik: 25 √ó 8 ka√ß eder?",
            "Bug√ºn hava durumu nasƒ±l?",
            "Einstein kimdir?",
            "T√ºrkiye'nin ba≈ükenti neresi?"
        ]
        
        successful_non_file_questions = 0
        
        for question in non_file_questions:
            print(f"   Testing non-file question: '{question}'...")
            
            success, response = self.run_test(
                f"Send Non-File Question: '{question}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": question, "mode": "chat"}
            )
            
            if success:
                ai_response = response.get('content', '')
                print(f"     Response: {ai_response[:100]}...")
                
                # Check if response uses normal hybrid system (not file content)
                normal_system_indicators = [
                    'web ara≈ütƒ±rmasƒ±', 'merhaba', 'nasƒ±lsƒ±n', '200', 'einstein',
                    'ankara'  # This should come from general knowledge, not file
                ]
                
                # For math questions, check for correct answer
                if '25 √ó 8' in question or '25 x 8' in question:
                    if '200' in ai_response:
                        print("     ‚úÖ Math question answered correctly (normal system)")
                        successful_non_file_questions += 1
                    else:
                        print("     ‚ùå Math question not answered correctly")
                
                # For general questions, check they don't reference uploaded file
                elif not any(file_ref in ai_response.lower() for file_ref in ['y√ºklediƒüiniz dosya', 'pdf', 'belgede']):
                    print("     ‚úÖ Normal system used (no file references)")
                    successful_non_file_questions += 1
                else:
                    print("     ‚ùå File content appears to be used inappropriately")
            
            time.sleep(2)  # Brief pause between questions
        
        if successful_non_file_questions >= len(non_file_questions) * 0.6:  # 60% success rate
            self.file_tests_passed += 1
            print(f"‚úÖ PASSED: Non-file questions handled correctly ({successful_non_file_questions}/{len(non_file_questions)})")
            return True, test_conv_id
        else:
            print(f"‚ùå FAILED: Non-file questions not handled properly ({successful_non_file_questions}/{len(non_file_questions)})")
            return False, test_conv_id

    def test_contextual_mixed_conversation_flow(self):
        """Test Scenario 4: Mixed Conversation Flow"""
        print("\nüß™ CONTEXTUAL FILE PROCESSING TEST 4: Mixed Conversation Flow")
        
        # Create new conversation for mixed flow test
        success, response = self.run_test(
            "Create Conversation for Mixed Flow Test",
            "POST",
            "conversations",
            200,
            data={"title": "Mixed Conversation Flow Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Step 1: Upload a PDF ‚Üí system message
        print("   Step 1: Upload PDF...")
        test_file_path = self.create_test_file("pdf", "Test PDF i√ßeriƒüi: Yapay zeka teknolojisi hƒ±zla geli≈üiyor.")
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            with open(test_file_path, 'rb') as file:
                files = {'file': ('mixed_test.pdf', file, 'application/pdf')}
                upload_response = requests.post(url, files=files, timeout=30)
            
            if upload_response.status_code != 200:
                print("‚ùå File upload failed")
                return False
            
            print("   ‚úÖ PDF uploaded successfully")
            
            # Step 2: Ask "Bu PDF'i √∂zetle" ‚Üí should use file content
            print("   Step 2: Ask about PDF content...")
            success, response = self.run_test(
                "Ask about PDF: 'Bu PDF'i √∂zetle'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": "Bu PDF'i √∂zetle", "mode": "chat"}
            )
            
            file_content_used = False
            if success:
                ai_response = response.get('content', '')
                if any(indicator in ai_response.lower() for indicator in ['yapay zeka', 'teknoloji', 'pdf', 'i√ßerik']):
                    print("   ‚úÖ File content used for PDF question")
                    file_content_used = True
                else:
                    print("   ‚ùå File content not used for PDF question")
            
            time.sleep(2)
            
            # Step 3: Ask "Te≈üekk√ºrler" ‚Üí should NOT use file content
            print("   Step 3: Say thanks...")
            success, response = self.run_test(
                "Say thanks: 'Te≈üekk√ºrler'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": "Te≈üekk√ºrler", "mode": "chat"}
            )
            
            normal_response_1 = False
            if success:
                ai_response = response.get('content', '')
                if not any(file_ref in ai_response.lower() for file_ref in ['pdf', 'dosya', 'yapay zeka teknoloji']):
                    print("   ‚úÖ Normal response for thanks (no file content)")
                    normal_response_1 = True
                else:
                    print("   ‚ùå File content inappropriately used for thanks")
            
            time.sleep(2)
            
            # Step 4: Ask "25 + 30 ka√ß eder?" ‚Üí should NOT use file content
            print("   Step 4: Ask math question...")
            success, response = self.run_test(
                "Ask math: '25 + 30 ka√ß eder?'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": "25 + 30 ka√ß eder?", "mode": "chat"}
            )
            
            normal_response_2 = False
            if success:
                ai_response = response.get('content', '')
                if '55' in ai_response and not any(file_ref in ai_response.lower() for file_ref in ['pdf', 'dosya']):
                    print("   ‚úÖ Math answered correctly without file content")
                    normal_response_2 = True
                else:
                    print("   ‚ùå Math question not handled properly")
            
            time.sleep(2)
            
            # Step 5: Ask "Bu dosyada ba≈üka ne var?" ‚Üí should use file content again
            print("   Step 5: Ask about file content again...")
            success, response = self.run_test(
                "Ask about file: 'Bu dosyada ba≈üka ne var?'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": "Bu dosyada ba≈üka ne var?", "mode": "chat"}
            )
            
            file_content_used_again = False
            if success:
                ai_response = response.get('content', '')
                if any(indicator in ai_response.lower() for indicator in ['dosya', 'i√ßerik', 'yapay zeka', 'teknoloji']):
                    print("   ‚úÖ File content used again for file question")
                    file_content_used_again = True
                else:
                    print("   ‚ùå File content not used for second file question")
            
            # Evaluate overall mixed conversation flow
            successful_steps = sum([file_content_used, normal_response_1, normal_response_2, file_content_used_again])
            
            if successful_steps >= 3:  # At least 3 out of 4 steps successful
                self.file_tests_passed += 1
                print(f"‚úÖ PASSED: Mixed conversation flow working ({successful_steps}/4 steps)")
                return True
            else:
                print(f"‚ùå FAILED: Mixed conversation flow issues ({successful_steps}/4 steps)")
                return False
                
        except Exception as e:
            print(f"‚ùå FAILED: Mixed conversation flow error: {str(e)}")
            return False
        finally:
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def test_contextual_intelligent_detection(self):
        """Test intelligent detection of file-related vs non-file questions"""
        print("\nüß™ CONTEXTUAL FILE PROCESSING TEST 5: Intelligent Question Detection")
        
        # Create conversation and upload file
        success, response = self.run_test(
            "Create Conversation for Detection Test",
            "POST",
            "conversations",
            200,
            data={"title": "Intelligent Detection Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.file_tests_run += 1
        
        # Upload a test file first
        test_file_path = self.create_test_file("pdf", "Akƒ±llƒ± tespit sistemi i√ßin test i√ßeriƒüi.")
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            with open(test_file_path, 'rb') as file:
                files = {'file': ('detection_test.pdf', file, 'application/pdf')}
                upload_response = requests.post(url, files=files, timeout=30)
            
            if upload_response.status_code != 200:
                print("‚ùå File upload failed")
                return False
            
            # Test various questions to check intelligent detection
            test_cases = [
                # Should use file content
                ("Bu PDF'te ne yazƒ±yor?", True, "Direct file reference"),
                ("Dosyayƒ± √∂zetle", True, "File processing action"),
                ("Y√ºklediƒüim belgeyi analiz et", True, "Uploaded document reference"),
                
                # Should NOT use file content  
                ("Merhaba", False, "Casual greeting"),
                ("Bug√ºn hava nasƒ±l?", False, "Current weather"),
                ("Einstein kimdir?", False, "General knowledge"),
                ("50 √ó 2 ka√ß eder?", False, "Math calculation")
            ]
            
            successful_detections = 0
            
            for question, should_use_file, description in test_cases:
                print(f"   Testing: '{question}' ({description})")
                
                success, response = self.run_test(
                    f"Detection Test: '{question}'",
                    "POST",
                    f"conversations/{test_conv_id}/messages",
                    200,
                    data={"content": question, "mode": "chat"}
                )
                
                if success:
                    ai_response = response.get('content', '')
                    
                    # Check if file content indicators are present
                    file_indicators = ['dosya', 'pdf', 'belge', 'i√ßerik', 'tespit sistemi', 'akƒ±llƒ±']
                    has_file_indicators = any(indicator in ai_response.lower() for indicator in file_indicators)
                    
                    if should_use_file and has_file_indicators:
                        print(f"     ‚úÖ Correctly used file content")
                        successful_detections += 1
                    elif not should_use_file and not has_file_indicators:
                        print(f"     ‚úÖ Correctly used normal system")
                        successful_detections += 1
                    else:
                        expected = "file content" if should_use_file else "normal system"
                        actual = "file content" if has_file_indicators else "normal system"
                        print(f"     ‚ùå Expected {expected}, got {actual}")
                
                time.sleep(1)
            
            detection_accuracy = successful_detections / len(test_cases)
            
            if detection_accuracy >= 0.7:  # 70% accuracy threshold
                self.file_tests_passed += 1
                print(f"‚úÖ PASSED: Intelligent detection working ({successful_detections}/{len(test_cases)} = {detection_accuracy:.1%})")
                return True
            else:
                print(f"‚ùå FAILED: Intelligent detection accuracy too low ({detection_accuracy:.1%})")
                return False
                
        except Exception as e:
            print(f"‚ùå FAILED: Intelligent detection test error: {str(e)}")
            return False
        finally:
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def run_contextual_file_processing_tests(self):
        """Run all contextual file processing system tests"""
        print("\n" + "="*70)
        print("üöÄ STARTING IMPROVED CONTEXTUAL FILE PROCESSING SYSTEM TESTS")
        print("Testing IMPROVED file processing with contextual usage:")
        print("1. PDF Upload ‚Üí One-time system message")
        print("2. File-related questions ‚Üí Use file content")
        print("3. Non-file questions ‚Üí Use normal hybrid system")
        print("4. Mixed conversation flow ‚Üí Smart context switching")
        print("5. Intelligent question detection ‚Üí is_question_about_uploaded_file()")
        print("="*70)
        
        contextual_tests = [
            self.test_contextual_file_upload_system_message,
            self.test_contextual_file_related_questions,
            self.test_contextual_non_file_questions,
            self.test_contextual_mixed_conversation_flow,
            self.test_contextual_intelligent_detection
        ]
        
        for test in contextual_tests:
            try:
                test()
                time.sleep(3)  # Longer pause between contextual tests
            except Exception as e:
                print(f"‚ùå Contextual file processing test failed with exception: {e}")
        
        return True

    def run_file_processing_tests(self):
        """Run all file processing system tests"""
        print("\n" + "="*60)
        print("üöÄ STARTING NEW FILE PROCESSING SYSTEM TESTS")
        print("Testing NEW file processing features:")
        print("1. File Upload Endpoints (POST /api/conversations/{id}/upload)")
        print("2. File List Endpoint (GET /api/conversations/{id}/files)")
        print("3. OpenAI GPT-4o Mini Integration")
        print("4. File Content Extraction")
        print("5. Smart Routing with File Processing")
        print("="*60)
        
        file_tests = [
            self.test_file_upload_endpoint,
            self.test_file_list_endpoint,
            self.test_file_size_validation,
            self.test_file_type_validation,
            self.test_openai_integration,
            self.test_smart_routing_file_vs_normal,
            self.test_file_processing_keywords,
            self.test_emergent_llm_key_configuration
        ]
        
        for test in file_tests:
            try:
                test()
                time.sleep(2)  # Brief pause between tests
            except Exception as e:
                print(f"‚ùå File processing test failed with exception: {e}")
        
        # Run contextual file processing tests
        self.run_contextual_file_processing_tests()
        
        # Print file processing test results
        print("\n" + "="*60)
        print(f"üìÅ FILE PROCESSING SYSTEM RESULTS: {self.file_tests_passed}/{self.file_tests_run} tests passed")
        
        if self.file_tests_passed == self.file_tests_run:
            print("üéâ All file processing system tests passed!")
            print("‚úÖ File upload endpoints working")
            print("‚úÖ OpenAI GPT-4o mini integration working")
            print("‚úÖ File validation working")
            print("‚úÖ Smart routing with file processing working")
            print("‚úÖ Contextual file usage working")
        else:
            print(f"‚ùå {self.file_tests_run - self.file_tests_passed} file processing tests failed")
        
        return self.file_tests_passed == self.file_tests_run

    def test_technical_creative_routing_scenario_1(self):
        """Test Scenario 1: Technical/Creative Questions ‚Üí Direct OpenAI API (GPT-4o)"""
        print("\nüß™ NEW ROUTING TEST 1: Technical/Creative Questions (Direct OpenAI API)")
        
        # Create conversation for technical/creative test
        success, response = self.run_test(
            "Create Conversation for Technical/Creative Test",
            "POST",
            "conversations",
            200,
            data={"title": "Technical Creative Routing Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.routing_tests_run += 1
        
        # Test technical/creative questions that should use Direct OpenAI API
        technical_creative_questions = [
            "Bana bir blog yazƒ±sƒ± yaz",
            "Bu metni d√ºzelt: 'Bug√ºn hava √ßok g√ºzeldi ama yaƒümur yaƒüƒ±yor.'",
            "√ñzge√ßmi≈üimi iyile≈ütir",
            "Bu c√ºmleyi ƒ∞ngilizceye √ßevir: 'Merhaba nasƒ±lsƒ±n?'",
            "Bir i≈ü planƒ± hazƒ±rla",
            "Bu yazƒ±mdaki yazƒ±m hatalarƒ±nƒ± d√ºzelt"
        ]
        
        successful_technical_tests = 0
        
        for question in technical_creative_questions:
            print(f"   Testing technical/creative question: '{question}'...")
            
            start_time = time.time()
            success, response = self.run_test(
                f"Send Technical/Creative Question: '{question}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": question, "mode": "chat"}
            )
            response_time = time.time() - start_time
            
            if success:
                ai_response = response.get('content', '')
                print(f"     Response Time: {response_time:.2f} seconds")
                print(f"     Response: {ai_response[:100]}...")
                
                # Check if response indicates technical/creative processing
                # Should NOT contain web search indicators for these questions
                web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel web', 'kaynaklarƒ±ndan']
                has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
                
                # Should contain appropriate technical/creative response
                creative_indicators = ['yazƒ±', 'metin', 'd√ºzelt', '√ßevir', 'plan', 'iyile≈ütir', 'hello', 'how are you']
                has_creative_response = any(indicator in ai_response.lower() for indicator in creative_indicators)
                
                if has_creative_response and not has_web_indicators:
                    print("     ‚úÖ Technical/creative question handled correctly (Direct OpenAI API)")
                    successful_technical_tests += 1
                elif has_web_indicators:
                    print("     ‚ùå Web search used instead of Direct OpenAI API")
                else:
                    print("     ‚ö†Ô∏è  Response doesn't clearly indicate technical/creative processing")
                    successful_technical_tests += 0.5  # Partial credit
            
            time.sleep(2)  # Brief pause between tests
        
        if successful_technical_tests >= len(technical_creative_questions) * 0.7:  # 70% success rate
            self.routing_tests_passed += 1
            print(f"‚úÖ PASSED: Technical/Creative routing working ({successful_technical_tests}/{len(technical_creative_questions)})")
            return True
        else:
            print(f"‚ùå FAILED: Technical/Creative routing issues ({successful_technical_tests}/{len(technical_creative_questions)})")
            return False

    def test_file_content_routing_scenario_2(self):
        """Test Scenario 2: File Content Questions ‚Üí OpenAI GPT-4o mini (EMERGENT_LLM_KEY)"""
        print("\nüß™ NEW ROUTING TEST 2: File Content Questions (OpenAI GPT-4o mini)")
        
        # Create conversation and upload a file
        success, response = self.run_test(
            "Create Conversation for File Content Test",
            "POST",
            "conversations",
            200,
            data={"title": "File Content Routing Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.routing_tests_run += 1
        
        # Upload a test file first
        test_file_path = self.create_test_file("pdf", "Test dosya i√ßeriƒüi: Bu bir √∂rnek PDF dosyasƒ±dƒ±r. ƒ∞√ßerisinde √∂nemli bilgiler bulunmaktadƒ±r.")
        
        try:
            url = f"{self.base_url}/conversations/{test_conv_id}/upload"
            with open(test_file_path, 'rb') as file:
                files = {'file': ('routing_test.pdf', file, 'application/pdf')}
                upload_response = requests.post(url, files=files, timeout=30)
            
            if upload_response.status_code != 200:
                print("‚ùå File upload failed")
                return False
            
            print("   ‚úÖ Test file uploaded successfully")
            
            # Test file content questions that should use OpenAI GPT-4o mini
            file_content_questions = [
                "Bu PDF'i √∂zetle",
                "Dosyayƒ± analiz et", 
                "Excel verilerini incele"
            ]
            
            successful_file_tests = 0
            
            for question in file_content_questions:
                print(f"   Testing file content question: '{question}'...")
                
                start_time = time.time()
                success, response = self.run_test(
                    f"Send File Content Question: '{question}'",
                    "POST",
                    f"conversations/{test_conv_id}/messages",
                    200,
                    data={"content": question, "mode": "chat"}
                )
                response_time = time.time() - start_time
                
                if success:
                    ai_response = response.get('content', '')
                    print(f"     Response Time: {response_time:.2f} seconds")
                    print(f"     Response: {ai_response[:100]}...")
                    
                    # Check if response indicates file processing with OpenAI GPT-4o mini
                    file_processing_indicators = ['dosya', 'pdf', 'i√ßerik', 'analiz', '√∂zet', 'excel']
                    has_file_processing = any(indicator in ai_response.lower() for indicator in file_processing_indicators)
                    
                    # Should NOT use web search for file content questions
                    web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel web']
                    has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
                    
                    if has_file_processing and not has_web_indicators:
                        print("     ‚úÖ File content question handled correctly (OpenAI GPT-4o mini)")
                        successful_file_tests += 1
                    elif has_web_indicators:
                        print("     ‚ùå Web search used instead of OpenAI GPT-4o mini")
                    else:
                        print("     ‚ö†Ô∏è  Response doesn't clearly indicate file processing")
                        successful_file_tests += 0.5  # Partial credit
                
                time.sleep(2)
            
            if successful_file_tests >= len(file_content_questions) * 0.7:  # 70% success rate
                self.routing_tests_passed += 1
                print(f"‚úÖ PASSED: File content routing working ({successful_file_tests}/{len(file_content_questions)})")
                return True
            else:
                print(f"‚ùå FAILED: File content routing issues ({successful_file_tests}/{len(file_content_questions)})")
                return False
                
        except Exception as e:
            print(f"‚ùå FAILED: File content routing error: {str(e)}")
            return False
        finally:
            if os.path.exists(test_file_path):
                os.remove(test_file_path)

    def test_current_info_routing_scenario_3(self):
        """Test Scenario 3: Current Information ‚Üí Web Search"""
        print("\nüß™ NEW ROUTING TEST 3: Current Information (Web Search)")
        
        # Create conversation for current info test
        success, response = self.run_test(
            "Create Conversation for Current Info Test",
            "POST",
            "conversations",
            200,
            data={"title": "Current Info Routing Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.routing_tests_run += 1
        
        # Test current information questions that should use Web Search
        current_info_questions = [
            "Bug√ºn hava durumu nasƒ±l?",
            "Dolar kuru ka√ß TL?",
            "Son haberler neler?"
        ]
        
        successful_current_tests = 0
        
        for question in current_info_questions:
            print(f"   Testing current info question: '{question}'...")
            
            start_time = time.time()
            success, response = self.run_test(
                f"Send Current Info Question: '{question}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": question, "mode": "chat"}
            )
            response_time = time.time() - start_time
            
            if success:
                ai_response = response.get('content', '')
                print(f"     Response Time: {response_time:.2f} seconds")
                print(f"     Response: {ai_response[:100]}...")
                
                # Check if response indicates web search was used
                web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel', 'hava', 'dolar', 'tl', 'haber', 'sonu√ß']
                has_web_indicators = any(indicator in ai_response.lower() for indicator in web_indicators)
                
                # Check for current information content
                current_info_indicators = ['bug√ºn', '≈üu an', 'g√ºncel', 'son', 'hava durumu', 'kur', 'haberler']
                has_current_info = any(indicator in ai_response.lower() for indicator in current_info_indicators)
                
                if has_web_indicators or has_current_info:
                    print("     ‚úÖ Current info question handled correctly (Web Search)")
                    successful_current_tests += 1
                else:
                    print("     ‚ùå Web search not used for current information")
            
            time.sleep(2)
        
        if successful_current_tests >= len(current_info_questions) * 0.7:  # 70% success rate
            self.routing_tests_passed += 1
            print(f"‚úÖ PASSED: Current info routing working ({successful_current_tests}/{len(current_info_questions)})")
            return True
        else:
            print(f"‚ùå FAILED: Current info routing issues ({successful_current_tests}/{len(current_info_questions)})")
            return False

    def test_normal_questions_routing_scenario_4(self):
        """Test Scenario 4: Normal Questions ‚Üí AnythingLLM (hybrid system)"""
        print("\nüß™ NEW ROUTING TEST 4: Normal Questions (AnythingLLM hybrid system)")
        
        # Create conversation for normal questions test
        success, response = self.run_test(
            "Create Conversation for Normal Questions Test",
            "POST",
            "conversations",
            200,
            data={"title": "Normal Questions Routing Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.routing_tests_run += 1
        
        # Test normal questions that should use AnythingLLM hybrid system
        normal_questions = [
            "Merhaba nasƒ±lsƒ±n?",
            "25 √ó 8 ka√ß eder?",
            "Einstein kimdir?"
        ]
        
        successful_normal_tests = 0
        
        for question in normal_questions:
            print(f"   Testing normal question: '{question}'...")
            
            start_time = time.time()
            success, response = self.run_test(
                f"Send Normal Question: '{question}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": question, "mode": "chat"}
            )
            response_time = time.time() - start_time
            
            if success:
                ai_response = response.get('content', '')
                print(f"     Response Time: {response_time:.2f} seconds")
                print(f"     Response: {ai_response[:100]}...")
                
                # Check for appropriate responses to normal questions
                if "merhaba" in question.lower():
                    # Should get a greeting response
                    greeting_indicators = ['merhaba', 'selam', 'nasƒ±lsƒ±n', 'yardƒ±m']
                    if any(indicator in ai_response.lower() for indicator in greeting_indicators):
                        print("     ‚úÖ Greeting handled correctly (AnythingLLM)")
                        successful_normal_tests += 1
                    else:
                        print("     ‚ùå Inappropriate greeting response")
                
                elif "25 √ó 8" in question or "25 x 8" in question:
                    # Should get correct math answer
                    if '200' in ai_response:
                        print("     ‚úÖ Math question answered correctly (AnythingLLM)")
                        successful_normal_tests += 1
                    else:
                        print("     ‚ùå Math question not answered correctly")
                
                elif "einstein" in question.lower():
                    # Should get information about Einstein
                    einstein_indicators = ['einstein', 'fizik', 'bilim', 'g√∂relilik', 'alman']
                    if any(indicator in ai_response.lower() for indicator in einstein_indicators):
                        print("     ‚úÖ Einstein question handled correctly (AnythingLLM)")
                        successful_normal_tests += 1
                    else:
                        print("     ‚ùå Einstein question not handled properly")
            
            time.sleep(2)
        
        if successful_normal_tests >= len(normal_questions) * 0.7:  # 70% success rate
            self.routing_tests_passed += 1
            print(f"‚úÖ PASSED: Normal questions routing working ({successful_normal_tests}/{len(normal_questions)})")
            return True
        else:
            print(f"‚ùå FAILED: Normal questions routing issues ({successful_normal_tests}/{len(normal_questions)})")
            return False

    def test_technical_creative_function_detection(self):
        """Test is_technical_or_creative_question() function accuracy"""
        print("\nüß™ NEW ROUTING TEST 5: Technical/Creative Function Detection")
        
        # Create conversation for function detection test
        success, response = self.run_test(
            "Create Conversation for Function Detection Test",
            "POST",
            "conversations",
            200,
            data={"title": "Function Detection Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.routing_tests_run += 1
        
        # Test various questions to verify is_technical_or_creative_question() detection
        test_cases = [
            # Should be detected as technical/creative (True)
            ("Bana bir makale yaz", True, "Writing request"),
            ("Bu metni d√ºzelt", True, "Text correction"),
            ("√ñzge√ßmi≈üimi iyile≈ütir", True, "CV improvement"),
            ("ƒ∞ngilizceye √ßevir", True, "Translation"),
            ("Bir plan hazƒ±rla", True, "Planning"),
            
            # Should NOT be detected as technical/creative (False)
            ("Merhaba nasƒ±lsƒ±n", False, "Greeting"),
            ("25 + 30 ka√ß eder", False, "Math"),
            ("Einstein kimdir", False, "General knowledge"),
            ("Bug√ºn hava nasƒ±l", False, "Current info"),
            ("Dolar kuru ka√ß TL", False, "Current info")
        ]
        
        successful_detections = 0
        
        for question, should_be_technical, description in test_cases:
            print(f"   Testing detection: '{question}' ({description})")
            
            success, response = self.run_test(
                f"Detection Test: '{question}'",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": question, "mode": "chat"}
            )
            
            if success:
                ai_response = response.get('content', '')
                
                # Analyze response to infer which system was used
                web_indicators = ['web ara≈ütƒ±rmasƒ±', 'g√ºncel web']
                creative_indicators = ['yaz', 'd√ºzelt', 'iyile≈ütir', '√ßevir', 'plan', 'hello', 'how are you']
                math_indicators = ['55', '200', 'eder', 'sonu√ß']
                greeting_indicators = ['merhaba', 'selam', 'yardƒ±m']
                
                has_web = any(indicator in ai_response.lower() for indicator in web_indicators)
                has_creative = any(indicator in ai_response.lower() for indicator in creative_indicators)
                has_math = any(indicator in ai_response.lower() for indicator in math_indicators)
                has_greeting = any(indicator in ai_response.lower() for indicator in greeting_indicators)
                
                # Infer which system was used based on response characteristics
                if should_be_technical:
                    # Should use Direct OpenAI API (creative/technical response)
                    if has_creative and not has_web:
                        print(f"     ‚úÖ Correctly detected as technical/creative")
                        successful_detections += 1
                    else:
                        print(f"     ‚ùå Not detected as technical/creative")
                else:
                    # Should NOT use Direct OpenAI API
                    if (has_web and "bug√ºn" in question.lower()) or \
                       (has_web and "dolar" in question.lower()) or \
                       (has_math and ("25" in question or "30" in question)) or \
                       (has_greeting and "merhaba" in question.lower()) or \
                       ("einstein" in ai_response.lower() and "einstein" in question.lower()):
                        print(f"     ‚úÖ Correctly NOT detected as technical/creative")
                        successful_detections += 1
                    else:
                        print(f"     ‚ùå Incorrectly detected as technical/creative")
            
            time.sleep(1.5)
        
        detection_accuracy = successful_detections / len(test_cases)
        
        if detection_accuracy >= 0.8:  # 80% accuracy
            self.routing_tests_passed += 1
            print(f"‚úÖ PASSED: Technical/Creative detection accuracy: {detection_accuracy:.1%}")
            return True
        else:
            print(f"‚ùå FAILED: Technical/Creative detection accuracy too low: {detection_accuracy:.1%}")
            return False

    def run_new_routing_system_tests(self):
        """Run all NEW TECHNICAL/CREATIVE QUESTION ROUTING system tests"""
        print("\n" + "="*70)
        print("üöÄ STARTING NEW TECHNICAL/CREATIVE QUESTION ROUTING SYSTEM TESTS")
        print("Testing 4-tier priority routing system:")
        print("1. Teknik/Yaratƒ±cƒ± Sorular ‚Üí Direkt OpenAI API (GPT-4o)")
        print("2. Dosya ƒ∞√ßeriƒüi Sorularƒ± ‚Üí OpenAI GPT-4o mini (EMERGENT_LLM_KEY)")
        print("3. G√ºncel Bilgi ‚Üí Web Search")
        print("4. Diƒüer Sorular ‚Üí AnythingLLM (hibrit sistem)")
        print("="*70)
        
        # Initialize routing test counters
        self.routing_tests_run = 0
        self.routing_tests_passed = 0
        
        routing_tests = [
            self.test_technical_creative_routing_scenario_1,
            self.test_file_content_routing_scenario_2,
            self.test_current_info_routing_scenario_3,
            self.test_normal_questions_routing_scenario_4,
            self.test_technical_creative_function_detection
        ]
        
        for test in routing_tests:
            try:
                test()
                time.sleep(3)  # Longer pause between routing tests
            except Exception as e:
                print(f"‚ùå Routing test failed with exception: {e}")
        
        # Print routing system test results
        print("\n" + "="*70)
        print(f"üß™ NEW ROUTING SYSTEM RESULTS: {self.routing_tests_passed}/{self.routing_tests_run} tests passed")
        
        if self.routing_tests_passed == self.routing_tests_run:
            print("üéâ All NEW routing system tests passed!")
            print("‚úÖ Technical/Creative ‚Üí Direct OpenAI API working")
            print("‚úÖ File Content ‚Üí OpenAI GPT-4o mini working")
            print("‚úÖ Current Info ‚Üí Web Search working")
            print("‚úÖ Normal Questions ‚Üí AnythingLLM working")
            print("‚úÖ is_technical_or_creative_question() function working")
        else:
            print(f"‚ùå {self.routing_tests_run - self.routing_tests_passed} routing system tests failed")
        
        return self.routing_tests_passed == self.routing_tests_run

    def test_conversation_mode_friend(self):
        """Test NEW CONVERSATION MODE 1: Friend (Arkada≈ü Canlƒ±sƒ±) with direct ChatGPT API"""
        print("\nüß™ NEW CONVERSATION MODE TEST 1: Friend (Arkada≈ü Canlƒ±sƒ±)")
        
        # Create conversation for friend mode test
        success, response = self.run_test(
            "Create Conversation for Friend Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Friend Mode Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test friend mode with motivational question
        start_time = time.time()
        success, response = self.run_test(
            "Send Friend Mode Question: 'Bug√ºn √ßok yorgunum, motivasyona ihtiyacƒ±m var'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Bug√ºn √ßok yorgunum, motivasyona ihtiyacƒ±m var", "mode": "chat", "conversationMode": "friend"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for friend mode characteristics
            friend_indicators = [
                'arkada≈ü', 'dostum', 'canƒ±m', 'motivasyon', 'ba≈üarabilirsin', 
                'yanƒ±ndayƒ±m', 'g√º√ßl√ºs√ºn', 'pozitif', 'umut', 'enerji', 'motive'
            ]
            
            has_friend_tone = any(indicator in ai_response.lower() for indicator in friend_indicators)
            
            # Check that it's distinctly different from normal responses (should be more personal/motivational)
            if has_friend_tone and len(ai_response) > 50:
                print("‚úÖ PASSED: Friend mode personality detected (samimi, motive edici, esprili)")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Friend mode personality not detected")
                return False
        
        return False

    def test_conversation_mode_realistic(self):
        """Test NEW CONVERSATION MODE 2: Realistic (Ger√ßek√ßi) with direct ChatGPT API"""
        print("\nüß™ NEW CONVERSATION MODE TEST 2: Realistic (Ger√ßek√ßi)")
        
        # Create conversation for realistic mode test
        success, response = self.run_test(
            "Create Conversation for Realistic Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Realistic Mode Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test realistic mode with business question
        start_time = time.time()
        success, response = self.run_test(
            "Send Realistic Mode Question: 'Yeni bir i≈ü kurmayƒ± d√º≈ü√ºn√ºyorum'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Yeni bir i≈ü kurmayƒ± d√º≈ü√ºn√ºyorum", "mode": "chat", "conversationMode": "realistic"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for realistic mode characteristics
            realistic_indicators = [
                'risk', 'zorluk', 'ger√ßek', 'dikkat', 'analiz', 'ele≈ütirel',
                'g√º√ßl√º y√∂n', 'zayƒ±f y√∂n', 'kanƒ±t', 'objektif', 'pratik', 'test'
            ]
            
            has_realistic_tone = any(indicator in ai_response.lower() for indicator in realistic_indicators)
            
            # Check for critical thinking approach
            if has_realistic_tone and len(ai_response) > 50:
                print("‚úÖ PASSED: Realistic mode personality detected (ele≈ütirel, kanƒ±t odaklƒ±)")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Realistic mode personality not detected")
                return False
        
        return False

    def test_conversation_mode_coach(self):
        """Test NEW CONVERSATION MODE 3: Coach (Ko√ß) with direct ChatGPT API"""
        print("\nüß™ NEW CONVERSATION MODE TEST 3: Coach (Ko√ß)")
        
        # Create conversation for coach mode test
        success, response = self.run_test(
            "Create Conversation for Coach Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Coach Mode Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test coach mode with goal-setting question
        start_time = time.time()
        success, response = self.run_test(
            "Send Coach Mode Question: 'Hedeflerime nasƒ±l ula≈üabilirim?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Hedeflerime nasƒ±l ula≈üabilirim?", "mode": "chat", "conversationMode": "coach"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for coach mode characteristics
            coach_indicators = [
                'hedef', 'adƒ±m', 'plan', 'nasƒ±l', 'hangi', 'ne d√º≈ü√ºn√ºyorsun',
                'potansiyel', 'geli≈üim', 'aksiyon', 'strateji', 'mentor', 'ko√ß'
            ]
            
            # Check for question-asking approach (coaches ask questions)
            question_count = ai_response.count('?')
            has_coach_tone = any(indicator in ai_response.lower() for indicator in coach_indicators)
            
            if has_coach_tone and question_count >= 1 and len(ai_response) > 50:
                print("‚úÖ PASSED: Coach mode personality detected (soru soran, d√º≈ü√ºnd√ºren, hedef odaklƒ±)")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Coach mode personality not detected")
                return False
        
        return False

    def test_conversation_mode_lawyer(self):
        """Test NEW CONVERSATION MODE 4: Lawyer (Hukuk√ßu) with direct ChatGPT API"""
        print("\nüß™ NEW CONVERSATION MODE TEST 4: Lawyer (Hukuk√ßu)")
        
        # Create conversation for lawyer mode test
        success, response = self.run_test(
            "Create Conversation for Lawyer Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Lawyer Mode Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test lawyer mode with decision question
        start_time = time.time()
        success, response = self.run_test(
            "Send Lawyer Mode Question: 'Bu durumda nasƒ±l hareket etmeliyim?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Bu durumda nasƒ±l hareket etmeliyim?", "mode": "chat", "conversationMode": "lawyer"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for lawyer mode characteristics
            lawyer_indicators = [
                'analiz', 'risk', 'kar≈üƒ± arg√ºman', 'lehte', 'aleyhte', 'kanƒ±t',
                'detay', 'sistematik', 'objektif', 'deƒüerlendirme', 'hukuk', 'yasal'
            ]
            
            has_lawyer_tone = any(indicator in ai_response.lower() for indicator in lawyer_indicators)
            
            if has_lawyer_tone and len(ai_response) > 50:
                print("‚úÖ PASSED: Lawyer mode personality detected (analitik, kar≈üƒ± arg√ºman √ºreten)")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Lawyer mode personality not detected")
                return False
        
        return False

    def test_conversation_mode_teacher(self):
        """Test NEW CONVERSATION MODE 5: Teacher (√ñƒüretmen) with direct ChatGPT API"""
        print("\nüß™ NEW CONVERSATION MODE TEST 5: Teacher (√ñƒüretmen)")
        
        # Create conversation for teacher mode test
        success, response = self.run_test(
            "Create Conversation for Teacher Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Teacher Mode Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test teacher mode with learning question
        start_time = time.time()
        success, response = self.run_test(
            "Send Teacher Mode Question: 'Python programlamayƒ± √∂ƒürenmek istiyorum'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Python programlamayƒ± √∂ƒürenmek istiyorum", "mode": "chat", "conversationMode": "teacher"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for teacher mode characteristics
            teacher_indicators = [
                'adƒ±m adƒ±m', '√∂nce', 'sonra', '√∂rnek', '√∂ƒüren', 'ders', 'a√ßƒ±kla',
                'basit', 'anla≈üƒ±lƒ±r', 'pratik', 'alƒ±≈ütƒ±rma', 'pedagojik', 'eƒüitim'
            ]
            
            has_teacher_tone = any(indicator in ai_response.lower() for indicator in teacher_indicators)
            
            # Check for structured learning approach
            if has_teacher_tone and len(ai_response) > 50:
                print("‚úÖ PASSED: Teacher mode personality detected (adƒ±m adƒ±m, √∂rnekli, pedagojik)")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Teacher mode personality not detected")
                return False
        
        return False

    def test_conversation_mode_minimalist(self):
        """Test NEW CONVERSATION MODE 6: Minimalist with direct ChatGPT API"""
        print("\nüß™ NEW CONVERSATION MODE TEST 6: Minimalist")
        
        # Create conversation for minimalist mode test
        success, response = self.run_test(
            "Create Conversation for Minimalist Mode Test",
            "POST",
            "conversations",
            200,
            data={"title": "Minimalist Mode Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test minimalist mode with information request
        start_time = time.time()
        success, response = self.run_test(
            "Send Minimalist Mode Question: 'Proje y√∂netimi hakkƒ±nda bilgi ver'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Proje y√∂netimi hakkƒ±nda bilgi ver", "mode": "chat", "conversationMode": "minimalist"}
        )
        
        response_time = time.time() - start_time
        
        if success:
            ai_response = response.get('content', '')
            print(f"   Response Time: {response_time:.2f} seconds")
            print(f"   AI Response: {ai_response[:200]}...")
            
            # Check for minimalist mode characteristics
            minimalist_indicators = [
                '‚Ä¢', '-', '1.', '2.', '3.', 'kƒ±sa', '√∂z', 'madde', 'liste'
            ]
            
            has_minimalist_format = any(indicator in ai_response for indicator in minimalist_indicators)
            is_concise = len(ai_response) < 300  # Should be shorter than other modes
            
            if has_minimalist_format and is_concise and len(ai_response) > 30:
                print("‚úÖ PASSED: Minimalist mode personality detected (kƒ±sa, √∂z, madde i≈üaretli)")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Minimalist mode personality not detected")
                return False
        
        return False

    def test_normal_mode_vs_conversation_modes(self):
        """Test that normal mode still uses AnythingLLM/hybrid system vs conversation modes using OpenAI"""
        print("\nüß™ CONVERSATION MODE TEST 7: Normal Mode vs Conversation Modes Routing")
        
        # Create conversation for comparison test
        success, response = self.run_test(
            "Create Conversation for Mode Comparison Test",
            "POST",
            "conversations",
            200,
            data={"title": "Mode Comparison Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test 1: Normal mode (should use AnythingLLM/hybrid)
        print("   Testing Normal Mode (should use AnythingLLM/hybrid)...")
        success1, response1 = self.run_test(
            "Send Normal Mode Question: 'Merhaba nasƒ±lsƒ±n?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Merhaba nasƒ±lsƒ±n?", "mode": "chat"}  # No conversationMode
        )
        
        time.sleep(2)
        
        # Test 2: Friend mode (should use direct OpenAI)
        print("   Testing Friend Mode (should use direct OpenAI)...")
        success2, response2 = self.run_test(
            "Send Friend Mode Question: 'Merhaba nasƒ±lsƒ±n?'",
            "POST",
            f"conversations/{test_conv_id}/messages",
            200,
            data={"content": "Merhaba nasƒ±lsƒ±n?", "mode": "chat", "conversationMode": "friend"}
        )
        
        if success1 and success2:
            normal_response = response1.get('content', '')
            friend_response = response2.get('content', '')
            
            print(f"   Normal Response: {normal_response[:100]}...")
            print(f"   Friend Response: {friend_response[:100]}...")
            
            # Check that responses are different (indicating different routing)
            responses_different = normal_response != friend_response
            
            # Check friend response has more personality
            friend_indicators = ['arkada≈ü', 'dostum', 'canƒ±m', 'g√ºzel', 'harika', 'motive']
            has_friend_personality = any(indicator in friend_response.lower() for indicator in friend_indicators)
            
            if responses_different and has_friend_personality:
                print("‚úÖ PASSED: Different routing confirmed - Normal uses hybrid, Friend uses OpenAI")
                self.conversation_mode_tests_passed += 1
                return True
            else:
                print("‚ùå FAILED: Routing difference not detected")
                return False
        
        return False

    def test_conversation_modes_personality_differences(self):
        """Test that different conversation modes produce distinctly different personalities"""
        print("\nüß™ CONVERSATION MODE TEST 8: Personality Differences Between Modes")
        
        # Create conversation for personality test
        success, response = self.run_test(
            "Create Conversation for Personality Test",
            "POST",
            "conversations",
            200,
            data={"title": "Personality Differences Test"}
        )
        
        if not success:
            return False
            
        test_conv_id = response.get('id')
        self.conversation_mode_tests_run += 1
        
        # Test same question in different modes
        test_question = "Stresli bir d√∂nemdeyim, ne yapmalƒ±yƒ±m?"
        
        modes_to_test = [
            ("friend", "arkada≈ü canlƒ±sƒ±"),
            ("realistic", "ger√ßek√ßi"),
            ("coach", "ko√ß"),
            ("teacher", "√∂ƒüretmen")
        ]
        
        responses = {}
        
        for mode, description in modes_to_test:
            print(f"   Testing {mode} mode ({description})...")
            success, response = self.run_test(
                f"Send Question in {mode} Mode",
                "POST",
                f"conversations/{test_conv_id}/messages",
                200,
                data={"content": test_question, "mode": "chat", "conversationMode": mode}
            )
            
            if success:
                ai_response = response.get('content', '')
                responses[mode] = ai_response
                print(f"     Response: {ai_response[:80]}...")
            
            time.sleep(2)  # Brief pause between tests
        
        # Check that all responses are different
        unique_responses = len(set(responses.values()))
        total_responses = len(responses)
        
        if unique_responses == total_responses and total_responses >= 3:
            print(f"‚úÖ PASSED: All {total_responses} conversation modes produced unique personalities")
            self.conversation_mode_tests_passed += 1
            return True
        else:
            print(f"‚ùå FAILED: Only {unique_responses}/{total_responses} unique responses - modes not sufficiently different")
            return False

    def run_conversation_mode_tests(self):
        """Run all NEW CONVERSATION MODE tests with direct ChatGPT API integration"""
        print("\n" + "="*70)
        print("üöÄ STARTING NEW CONVERSATION MODES TESTS")
        print("Testing DIRECT CHATGPT API INTEGRATION with personality prompts:")
        print("1. Friend (Arkada≈ü Canlƒ±sƒ±) - Samimi, motive edici, esprili")
        print("2. Realistic (Ger√ßek√ßi) - Ele≈ütirel, kanƒ±t odaklƒ±")
        print("3. Coach (Ko√ß) - Soru soran, d√º≈ü√ºnd√ºren, hedef odaklƒ±")
        print("4. Lawyer (Hukuk√ßu) - Analitik, kar≈üƒ± arg√ºman √ºreten")
        print("5. Teacher (√ñƒüretmen) - Adƒ±m adƒ±m, √∂rnekli, pedagojik")
        print("6. Minimalist - Kƒ±sa, √∂z, madde i≈üaretli")
        print("="*70)
        
        # Initialize conversation mode test counters
        self.conversation_mode_tests_run = 0
        self.conversation_mode_tests_passed = 0
        
        conversation_mode_tests = [
            self.test_conversation_mode_friend,
            self.test_conversation_mode_realistic,
            self.test_conversation_mode_coach,
            self.test_conversation_mode_lawyer,
            self.test_conversation_mode_teacher,
            self.test_conversation_mode_minimalist,
            self.test_normal_mode_vs_conversation_modes,
            self.test_conversation_modes_personality_differences
        ]
        
        for test in conversation_mode_tests:
            try:
                test()
                time.sleep(3)  # Longer pause between conversation mode tests
            except Exception as e:
                print(f"‚ùå Conversation mode test failed with exception: {e}")
        
        # Print conversation mode test results
        print("\n" + "="*70)
        print(f"üß™ NEW CONVERSATION MODES RESULTS: {self.conversation_mode_tests_passed}/{self.conversation_mode_tests_run} tests passed")
        
        if self.conversation_mode_tests_passed == self.conversation_mode_tests_run:
            print("üéâ All NEW CONVERSATION MODE tests passed!")
            print("‚úÖ Direct ChatGPT API integration working")
            print("‚úÖ All 6 conversation modes have distinct personalities")
            print("‚úÖ Normal mode still uses AnythingLLM/hybrid system")
            print("‚úÖ Personality prompts working correctly")
        else:
            print(f"‚ùå {self.conversation_mode_tests_run - self.conversation_mode_tests_passed} conversation mode tests failed")
        
        return self.conversation_mode_tests_passed == self.conversation_mode_tests_run

def main():
    print("üöÄ Starting Bƒ∞LGƒ∞N AI Backend API Tests")
    print("=" * 50)
    
    tester = BilginAIAPITester()
    
    # Run basic API tests first
    print("\nüìã BASIC API TESTS")
    print("-" * 30)
    basic_tests = [
        tester.test_root_endpoint,
        tester.test_get_conversations_empty,
        tester.test_create_conversation,
        tester.test_get_conversations_with_data,
        tester.test_get_messages_empty,
        tester.test_send_message,
        tester.test_get_messages_with_data,
        tester.test_send_second_message,
        tester.test_delete_conversation,
        tester.test_get_deleted_conversation
    ]
    
    for test in basic_tests:
        test()
    
    # Print basic test results
    print("\n" + "-" * 50)
    print(f"üìä Basic API Results: {tester.tests_passed}/{tester.tests_run} tests passed")
    
    # Run NEW conversation mode tests (PRIORITY)
    conversation_mode_success = tester.run_conversation_mode_tests()
    
    # Run NEW routing system tests
    routing_success = tester.run_new_routing_system_tests()
    
    # Run hybrid system tests
    hybrid_success = tester.run_hybrid_system_tests()
    
    # Run file processing system tests
    file_success = tester.run_file_processing_tests()
    
    # Print final comprehensive results
    total_tests = tester.tests_run + getattr(tester, 'conversation_mode_tests_run', 0) + tester.routing_tests_run + tester.hybrid_tests_run + tester.file_tests_run
    total_passed = tester.tests_passed + getattr(tester, 'conversation_mode_tests_passed', 0) + tester.routing_tests_passed + tester.hybrid_tests_passed + tester.file_tests_passed
    
    print("\n" + "=" * 60)
    print("üèÅ COMPREHENSIVE TEST RESULTS")
    print("=" * 60)
    print(f"üìã Basic API Tests: {tester.tests_passed}/{tester.tests_run} passed")
    print(f"üó£Ô∏è NEW Conversation Mode Tests: {getattr(tester, 'conversation_mode_tests_passed', 0)}/{getattr(tester, 'conversation_mode_tests_run', 0)} passed")
    print(f"üîÄ NEW Routing System Tests: {tester.routing_tests_passed}/{tester.routing_tests_run} passed")
    print(f"üß™ Hybrid System Tests: {tester.hybrid_tests_passed}/{tester.hybrid_tests_run} passed")
    print(f"üìÅ File Processing Tests: {tester.file_tests_passed}/{tester.file_tests_run} passed")
    print(f"üìä TOTAL: {total_passed}/{total_tests} tests passed")
    
    if total_passed == total_tests:
        print("üéâ ALL TESTS PASSED! Bƒ∞LGƒ∞N AI system is working correctly!")
        return 0
    else:
        failed_tests = total_tests - total_passed
        print(f"‚ùå {failed_tests} tests failed")
        
        if tester.tests_passed < tester.tests_run:
            print("   - Basic API issues detected")
        if tester.routing_tests_passed < tester.routing_tests_run:
            print("   - NEW Routing system issues detected")
        if tester.hybrid_tests_passed < tester.hybrid_tests_run:
            print("   - Hybrid system issues detected")
        if tester.file_tests_passed < tester.file_tests_run:
            print("   - File processing system issues detected")
            
        return 1

if __name__ == "__main__":
    sys.exit(main())